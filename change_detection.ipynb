{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdvBn0KMFgJO",
        "outputId": "0b6a5950-7049-4c2d-ea33-dff434872327"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as tr\n",
        "from model.change_detction_dataset import ChangeDetectionDataset, RandomFlip, RandomRot\n",
        "\n",
        "# Models\n",
        "from model.unet import Unet\n",
        "from model.siamunet_conc import SiamUnet_conc\n",
        "from model.siamunet_diff import SiamUnet_diff\n",
        "from model.fresunet import FresUNet\n",
        "from model.model import Model, ModelConfig\n",
        "\n",
        "# Other\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm as tqdm\n",
        "import time\n",
        "import warnings\n",
        "from pprint import pprint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134LZ1yhFgJR",
        "outputId": "aa18d84d-d235-4753-dff7-97581bca9d31"
      },
      "outputs": [],
      "source": [
        "# Global Variables' Definitions\n",
        "PATH_TO_DATASET = './dataset-lite/'\n",
        "MODEL_TYPE = 1 # 0-FC-EF | 1-FC-Siam-diff | 2-FC-Siam-conc | 3-FresUNet\n",
        "GPU_ENABLED = torch.cuda.is_available()\n",
        "LOAD_TRAINED = False\n",
        "\n",
        "\n",
        "#Cofniguration\n",
        "DATA_AUG = True\n",
        "BATCH_SIZE = 32\n",
        "PATCH_SIDE = 96\n",
        "N_EPOCHS = 50\n",
        "NORMALISE_IMGS = True\n",
        "TRAIN_STRIDE = int(PATCH_SIDE/2) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRZI66fGFgJV",
        "outputId": "62c40c09-0518-4830-fa2d-0ddf76c69a93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "499it [00:10, 49.27it/s]\n",
            "99it [00:03, 31.40it/s]\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "if DATA_AUG:\n",
        "    data_transform = tr.Compose([RandomFlip(), RandomRot()])\n",
        "else:\n",
        "    data_transform = None\n",
        "\n",
        "\n",
        "train_dataset = ChangeDetectionDataset(PATH_TO_DATASET, train = True, stride = TRAIN_STRIDE, transform=data_transform)\n",
        "weights = torch.FloatTensor(train_dataset.weights)\n",
        "if GPU_ENABLED:\n",
        "  weights = weights.cuda()\n",
        "  \n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "test_dataset = ChangeDetectionDataset(PATH_TO_DATASET, train = False, stride = TRAIN_STRIDE)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr88HmjBFgJX",
        "outputId": "e75bcb50-1495-4304-e803-d2ae3ecec792"
      },
      "outputs": [],
      "source": [
        "# 0-FC-EF | 1-FC-Siam-diff | 2-FC-Siam-conc | 3-FresUNet\n",
        "if MODEL_TYPE == 0:\n",
        "    net, net_name = Unet(2*3, 2), 'FC-EF'\n",
        "elif MODEL_TYPE == 1:\n",
        "    net, net_name = SiamUnet_diff(3, 2), 'FC-Siam-diff'\n",
        "elif MODEL_TYPE == 2:\n",
        "    net, net_name = SiamUnet_conc(3, 2), 'FC-Siam-conc'\n",
        "elif MODEL_TYPE == 3:\n",
        "    net, net_name = FresUNet(2*3, 2), 'FresUNet'\n",
        "\n",
        "if GPU_ENABLED:\n",
        "    net.cuda()\n",
        "\n",
        "criterion = nn.NLLLoss(weight=weights) # to be used with logsoftmax output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lE3ixBWFgJY",
        "outputId": "e0c0c462-c168-459c-b371-44a30a254cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: 1350146\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Number of trainable parameters:', count_parameters(net))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QMIQufikFgJZ"
      },
      "outputs": [],
      "source": [
        "model_config = ModelConfig(n_epochs=N_EPOCHS, gpu_enabled=GPU_ENABLED)\n",
        "model = Model(\n",
        "    model=net,\n",
        "    model_name=net_name,\n",
        "    config=model_config,\n",
        "    train_dataset=train_dataset,\n",
        "    train_loader=train_loader,\n",
        "    test_dataset=test_dataset,\n",
        "    criterion=criterion,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 of 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:06<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     t_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> 6\u001b[0m     out_dic \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m      7\u001b[0m     t_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(out_dic)\n",
            "File \u001b[1;32me:\\Ly\\VT\\Courses\\ECE 5424 - Advanced Machine Learning\\Project\\Codebase\\S23-AML-Project\\model\\model.py:87\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, save)\u001b[0m\n\u001b[0;32m     85\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     86\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(epoch_index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mn_epochs))\n\u001b[1;32m---> 87\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader,position\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     88\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining: \u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m/ \u001b[39m\u001b[39m{\u001b[39;00mtrain_loader_len\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m     I1 \u001b[39m=\u001b[39m Variable(batch[\u001b[39m\"\u001b[39m\u001b[39mI1\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfloat())\n",
            "File \u001b[1;32me:\\Ly\\VT\\Courses\\ECE 5424 - Advanced Machine Learning\\Project\\Codebase\\S23-AML-Project\\venv\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[1;32me:\\Ly\\VT\\Courses\\ECE 5424 - Advanced Machine Learning\\Project\\Codebase\\S23-AML-Project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
            "File \u001b[1;32me:\\Ly\\VT\\Courses\\ECE 5424 - Advanced Machine Learning\\Project\\Codebase\\S23-AML-Project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
            "File \u001b[1;32me:\\Ly\\VT\\Courses\\ECE 5424 - Advanced Machine Learning\\Project\\Codebase\\S23-AML-Project\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1045\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
            "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
            "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
            "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
            "File \u001b[1;32mC:\\Program Files\\Python39\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if LOAD_TRAINED:\n",
        "    net.load_state_dict(torch.load('net_final.pth.tar'))\n",
        "    print('LOAD OK')\n",
        "else:\n",
        "    t_start = time.time()\n",
        "    out_dic = model.train()\n",
        "    t_end = time.time()\n",
        "    print(out_dic)\n",
        "    print('Elapsed time:')\n",
        "    print(t_end - t_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f77Nz5HPFgJa"
      },
      "outputs": [],
      "source": [
        "if not LOAD_TRAINED:\n",
        "    torch.save(model.model.state_dict(), 'net_final.pth.tar')\n",
        "    print('SAVE OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lpK78RwyFgJb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "161it [00:15, 10.50it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m             io\u001b[39m.\u001b[39mimsave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnet_name\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,I, check_contrast\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m t_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 21\u001b[0m save_test_results(train_dataset)\n\u001b[1;32m     22\u001b[0m t_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mElapsed time: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(t_end \u001b[39m-\u001b[39m t_start))\n",
            "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36msave_test_results\u001b[0;34m(dset)\u001b[0m\n\u001b[1;32m     11\u001b[0m     I1 \u001b[39m=\u001b[39m I1\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     12\u001b[0m     I2 \u001b[39m=\u001b[39m I2\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 14\u001b[0m out \u001b[39m=\u001b[39m net(I1, I2)\n\u001b[1;32m     15\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(out\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m I \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack((\u001b[39m255\u001b[39m\u001b[39m*\u001b[39mcm,\u001b[39m255\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39msqueeze(predicted\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()),\u001b[39m255\u001b[39m\u001b[39m*\u001b[39mcm),\u001b[39m2\u001b[39m)\n",
            "File \u001b[0;32m~/VT/AML/change-detection/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VT/AML/change-detection/model/unet.py:101\u001b[0m, in \u001b[0;36mUnet.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Forward method.\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m# Stage 1\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m x11 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo11(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn11(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv11(x))))\n\u001b[1;32m    102\u001b[0m x12 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo12(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn12(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv12(x11))))\n\u001b[1;32m    103\u001b[0m x1p \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmax_pool2d(x12, kernel_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
            "File \u001b[0;32m~/VT/AML/change-detection/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/VT/AML/change-detection/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
            "File \u001b[0;32m~/VT/AML/change-detection/venv/lib/python3.11/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Test\n",
        "def save_test_results(dset):\n",
        "    for idx, name in tqdm(dset.names.iterrows()):\n",
        "        name = name[0]\n",
        "        with warnings.catch_warnings():\n",
        "            I1, I2, cm = dset.get_img(name)\n",
        "            I1 = Variable(torch.unsqueeze(I1, 0).float())\n",
        "            I2 = Variable(torch.unsqueeze(I2, 0).float())\n",
        "\n",
        "            if GPU_ENABLED:\n",
        "                I1 = I1.cuda()\n",
        "                I2 = I2.cuda()\n",
        "\n",
        "            out = net(I1, I2)\n",
        "            _, predicted = torch.max(out.data, 1)\n",
        "            I = np.stack((255*cm,255*np.squeeze(predicted.cpu().numpy()),255*cm),2)\n",
        "            I = I.astype(np.uint8)\n",
        "            io.imsave(f'{net_name}-{name}',I, check_contrast=False)\n",
        "\n",
        "t_start = time.time()\n",
        "save_test_results(train_dataset)\n",
        "t_end = time.time()\n",
        "print('Elapsed time: {}'.format(t_end - t_start))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "tD4xuXfSFgJc",
        "outputId": "d0184bcd-78f6-4ca6-f1c1-5c2811a318ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "63it [00:28,  2.20it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(train_dataset)\n\u001b[1;32m      2\u001b[0m pprint(results)\n",
            "File \u001b[0;32m~/VT/AML/change-detection/model/model.py:359\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, dset)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 l \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(cm\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m, i, j])\n\u001b[1;32m    358\u001b[0m                 class_correct[l] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m c[\u001b[39m0\u001b[39m, i, j]\n\u001b[0;32m--> 359\u001b[0m                 class_total[l] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    361\u001b[0m pr \u001b[39m=\u001b[39m (predicted\u001b[39m.\u001b[39mint() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    362\u001b[0m gt \u001b[39m=\u001b[39m (cm\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mint() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "results = model.evaluate(train_dataset)\n",
        "pprint(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'class_accuracy': [100.00000762939453, 0.0],\n",
            " 'dice': nan,\n",
            " 'kappa': 0.0,\n",
            " 'net_accuracy': 83.2217438052399,\n",
            " 'net_loss': 0.31093838810920715,\n",
            " 'precision': nan,\n",
            " 'recall': 0.0}\n"
          ]
        }
      ],
      "source": [
        "pprint(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
